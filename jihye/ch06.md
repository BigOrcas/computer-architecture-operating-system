# **Chapter 06 메모리와 캐시 메모리**

## 06-1 RAM의 특징과 종류

### RAM의 특징

- 실행할 프로그램의 명령어와 데이터가 저장된다.
- 휘발성 저장 장치이고, 실행할 대상을 저장한다.
    - 참고로, 보조 기억 장치는  비휘발성이고 보관할 대상을 저장한다.
- CPU는 보조기억장치에 직접 접근하지 못하기 때문에, CPU가 실행하고 싶은 프로그램이 보조기억장치에 있다면 이를 RAM으로 복사하여 저장한 뒤 실행한다.

### RAM의 용량과 성능

- RAM 용량이 적다면 보조기억장치에서 실행할 프로그램을 가져오는 일이 잦아 실행 시간이 길어진다.
- RAM 용량이 크면 많은 프로그램을 동시에 빠르게 실행하는 데 유리하다.
- 그렇지만 RAM 용량이 필요 이상으로 커졌을 때 속도가 그에 비례하여 증가하지는 않는다.

### RAM의 종류

- DRAM
    - Dynamic RAM
    - 저장된 데이터가 동적으로 변하는(사라지는) RAM
        - 시간이 지나면 저장된 데이터가 점차 사라지는 RAM
    - 따라서 데이터의 소멸을 막기 위해 일정 주기로 데이터를 재활성화(다시 저장) 해야 한다.
    - 대용량으로 설계하기가 용이하기 땜
- SRAM
    - Static RAM
    - 저장된 데이터가 변하지 않는 RAM
    - DRAM과 비교
        - 재활성화: 필요없음
        - 속도: 빠름
        - 가격:비쌈
        - 집적도: 낮음
        - 소비 전력: 높음
        - 사용 용도: 캐시 메모리
            - 대용량으로 만들어질 필요는 없지만 속도가 빨라야 하는 저장 장치
- SDRAM
    - Synchronous Dynamic RAM
    - 클럭 신호와 동기화된, 발전된 형태의 DRAM
        - 클럭 타이밍에 맞춰 CPU와 정보를 주고받을 수 있음을 의미한다. 즉, SDRM 은 클럭에 맞춰 동작하며 클럭마다 CPU와 정보를 주고받을 수 있다.
    - SDR SDRAM 이라고 부르기도 한다.
        - Single Data Rate SDRAM
- DDR SDRAM
    - Double Data Rate RAM
    - 최근 가장 흔히 사용된다.
    - 대역폭을 넓혀 속도를 빠르게 만든 SDRAM 이다.
        - 대역폭이란? 데이터를 주고받는 길의 너비
    - 한 클럭에 한 번 씩 CPU와 데이터를 주고받을 수 있는 SDRAM 에 비해 DDR SDRAM 은 두 배의 대역폭으로 한 클럭 당 두 번 씩 CPU와 데이터를 주고받을 수 있다.
        - DDR SDRAM의 전송속도가 2배 가량 빠르다.

## 06-2 메모리의 주소 공간

### 물리 주소와 논리 주소

- 물리 주소: 메모리 하드웨어가 사용하는 주소
- 논리 주소: CPU와 실행 중인 프로그램이 사용하는 주소
- CPU가 이해하는 주소가 논리 주소라고 해도 CPU가 메모리와 상호작용 하려면 논리주소와 물리 주소 간의 변환이 이루어져야 한다.
    - 변환없이는 CPU와 메모리는 서로 이해할 수 없는 주소 체계를 가지고 상호작용을 할 수 없기 때문
    - 논리주소는 어떻게 물리주소로 변환 될까?
        - CPU와 주소 버스 사이에 위치한 메모리 관리 장치(Memory Management Unit, MMU)라는 하드웨어에 의해 수행된다.
        - MMU는 CPU가 발생시킨 논리주소에 베이스 레지스터 값을 더하여 논리주소를 물리주소로 변환한다.
            - 베이스 레지스터는 프로그램의 가장 작은 물리주소, 즉 프로그램의 첫 물리 주소를 저장하는 셈이고 논리 주소는 프로그램의 시작점으로부터 떨어진 거리인 셈
- 논리 주소 범위를 벗어나는 명령어 실행을 방지하고, 실행 중인 프로그램이 다른 프로그램에 영향을 받지 않도록 보호할 방법이 필요한데 이를 한계 레지스터(limit register)가 담당한다.
    - 한계 레지스터는 논리주소의 최대 크기를 저장한다.
    - 한계 레지스터가 저장한 값보다 높은 주소 값에 접근하는 것은 프로그램의 범위에 벗어난 메모리 공간에 접근하는 것과 같다.
    - CPU는 메모리에 접근하기 전에 접근하고자 하는 논리 주소가 한계 레지스터보다 작은지를 항상 검사한다.
        - 만약 CPU가 한계 레지스터보다 높은 논리 주소에 접근하려고 하면 인터럽트(트랩)을 발생시켜 실행을 중단한다.

## 06-3 캐시 메모리

### 저장 장치 계층 구조

- 저장 장치는 일반적으로 아래와 같은 명제를 따른다.
    - CPU와 가까운 저장 장치는 빠르고, 멀리 있는 저장 장치는 느리다.
    - 속도가 빠른 저장 장치는 저장 용량이 작고, 가격이 비싸다.
- CPU에 얼마나 가까운가? 를 기준으로 계층적으로 나타낼 수 있고 이를 저장 장치 계층 구조(memory hierarchy)라고 한다.

### 캐시 메모리

- CPU와 메모리 사이에 위치하고 레지스터보다 용량이 크고 메모리보다 빠른 SRAM 기반의 저장 장치이다.
- 캐시 메모리는 CPU의 연산 속도와 메모리 접근 속도의 차이를 줄이기 위해 탄생했다.
- 캐시 메모리들은 여러 개가 있고, CPU(코어)와 가까운 순서대로 계층을 구성한다.
    - L1 캐시가 코어와 가장 가까운 캐시 메모리이다.
        - 일반적으로 L2 캐시와 코어 내부에 위치하고, L3 캐시는 코어 외부에 위치한다.
    - 캐시 메모리 용량은 L1,L2,L3 순으로 커지고 속도는 L3,L2,1 순으로 빨라진다.
    - L1 캐시와 L2 캐시는 코어마다 고유한 캐시 메모리로 할당되고, L3 캐시는 여러 코어가 공유하는 형태로 사용된다.

### 참조 지역성 원리

- CPU가 사용할 법한 대상을 예측하여 저장한다. 이 때 자주 사용될 것으로 예측한 데이터가 실제로 들어맞아 캐시 메모리 내 데이터가 CPU에 활용될 경우를 캐시 히트(cache hit)라고 한다.
    - 반대는 캐시 미스이고, 캐시 미스가 자주 발생하면 성능이 떨어진다.
        - 왜? 캐시 미스가 발생하면 CPU가 필요한 데이터를 메모리에서 직접 가져와야 하기 때문에 캐시 메모리의 이점을 활용할 수 없다.
- 캐시 적중률: 캐시가 히트되는 비율
    - 캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)
- CPU가 사용할 법한 데이터는 어떻게 알 수 있을까?
    - 캐시 메모리는 한 가지 원칙에 따라 메모리로부터 가져올 데이터를 결정한다. → 참조 지역성의 원리
- 참조 지역성의 원리
    - CPU가 메모리에 접근할 때의 주된 경향을 바탕으로 만들어진 원리
        1. CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향이 있다.
            1. 변수들을 여러 번 사용, 시간 지역성
        2. CPU는 접근한 메모리 공간 근처를 접근하려는 경향이 있다.
            1. CPU가 크롬을 실행할 때는 크롬 프로그램이 모여 있는 공간 근처를 집중적으로 접근할 것, 공간 지역성

---

### 내 생각

- 참조 지역성의 원리에 따라 CPU가 사용할 법한 데이터를 추측하는 게 신기하네요.

### 논의 내용
- 레디스의 정의는 무엇이고, 언제 사용하는 게 좋을까요?
- 레디스 캐시 전략에 대해서 아는 만큼만 설명해주세요.